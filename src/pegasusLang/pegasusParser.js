/* eslint-disable no-unused-vars  */
/* eslint-disable no-useless-escape  */
/* eslint-disable no-useless-concat  */

/**
 * LR parser generated by the Syntax tool.
 *
 * https://www.npmjs.com/package/syntax-cli
 *
 *   npm install -g syntax-cli
 *
 *   syntax-cli --help
 *
 * To regenerate run:
 *
 *   syntax-cli \
 *     --grammar ~/path-to-grammar-file \
 *     --mode <parsing-mode> \
 *     --output ~/path-to-output-parser-file.js
 */

/**
 * Matched token text.
 */
let yytext;

/**
 * Length of the matched token text.
 */
let yyleng;

/**
 * Storage object.
 */
let yy = {};

/**
 * Result of semantic action.
 */
let __;

/**
 * Result location object.
 */
let __loc;

function yyloc(start, end) {
  if (!yy.options.captureLocations) {
    return null;
  }

  // Epsilon doesn't produce location.
  if (!start || !end) {
    return start || end;
  }

  return {
    startOffset: start.startOffset,
    endOffset: end.endOffset,
    startLine: start.startLine,
    endLine: end.endLine,
    startColumn: start.startColumn,
    endColumn: end.endColumn,
  };
}

const EOF = "$";

/**
 * List of productions (generated by Syntax tool).
 */
const productions = [
  [
    -1,
    1,
    (_1) => {
      __ = _1;
    },
  ],
  [
    0,
    1,
    (_1) => {
      __ = {
        type: "Program",
        body: _1,
      };
    },
  ],
  [
    1,
    1,
    (_1) => {
      __ = _1;
    },
  ],
  [
    1,
    1,
    (_1) => {
      __ = _1;
    },
  ],
  [
    2,
    2,
    (_1, _2) => {
      __ = {
        type: "Resolver",
        name: _1,
        view: _2,
      };
    },
  ],
  [
    2,
    3,
    (_1, _2, _3) => {
      __ = {
        type: "Resolver",
        name: _1,
        experiment: _2,
        default: _3,
      };
    },
  ],
  [
    3,
    1,
    (_1) => {
      __ = {
        type: "StringLiteral",
        value: _1.slice(1, -1),
      };
    },
  ],
  [
    4,
    1,
    (_1) => {
      __ = _1;
    },
  ],
  [
    4,
    1,
    (_1) => {
      __ = _1;
    },
  ],
  [
    5,
    4,
    (_1, _2, _3, _4) => {
      __ = {
        type: "IfStatement",
        test: _2,
        consequent: _4,
        alternate: undefined,
      };
    },
  ],
  [
    6,
    6,
    (_1, _2, _3, _4, _5, _6) => {
      __ = {
        type: "IfStatement",
        test: _2,
        consequent: _4,
        alternate: _6,
      };
    },
  ],
  [
    6,
    6,
    (_1, _2, _3, _4, _5, _6) => {
      __ = {
        type: "IfStatement",
        test: _2,
        consequent: _4,
        alternate: _6,
      };
    },
  ],
  [
    7,
    1,
    (_1) => {
      __ = _1;
    },
  ],
  [
    7,
    3,
    (_1, _2, _3) => {
      __ = LogicalExpression(_1, _2, _3);
    },
  ],
  [
    8,
    1,
    (_1) => {
      __ = _1;
    },
  ],
  [
    8,
    3,
    (_1, _2, _3) => {
      __ = LogicalExpression(_1, _2, _3);
    },
  ],
  [
    9,
    3,
    (_1, _2, _3) => {
      __ = {
        type: "Equality",
        op: _2,
        field: _1,
        arg: _3.slice(1, -1),
      };
    },
  ],
  [
    10,
    1,
    (_1) => {
      __ = {
        type: "Identifier",
        value: _1,
      };
    },
  ],
];

/**
 * Encoded tokens map.
 */
const tokens = {
  STRING: "11",
  IF: "12",
  THEN: "13",
  ELSE: "14",
  IDENTIFIER: "15",
  "'show'": "16",
  "'useExperiment'": "17",
  "'or'": "18",
  "'and'": "19",
  "'equal'": "20",
  $: "21",
};

/**
 * Parsing table (generated by Syntax tool).
 */
const table = [
  { 0: 1, 1: 2, 2: 3, 4: 4, 5: 7, 6: 8, 12: "s9", 16: "s5", 17: "s6" },
  { 21: "acc" },
  { 21: "r1" },
  { 21: "r2" },
  { 21: "r3" },
  { 3: 10, 11: "s11" },
  { 3: 12, 11: "s11" },
  { 21: "r7" },
  { 21: "r8" },
  { 7: 14, 8: 15, 9: 16, 10: 17, 15: "s18" },
  { 14: "r4", 21: "r4" },
  { 11: "r6", 14: "r6", 21: "r6" },
  { 3: 13, 11: "s11" },
  { 14: "r5", 21: "r5" },
  { 13: "s19", 18: "s20" },
  { 13: "r12", 18: "r12", 19: "s26" },
  { 13: "r14", 18: "r14", 19: "r14" },
  { 20: "s28" },
  { 20: "r17" },
  { 2: 21, 16: "s5", 17: "s6" },
  { 8: 25, 9: 16, 10: 17, 15: "s18" },
  { 14: "s22", 21: "r9" },
  { 2: 23, 4: 24, 5: 7, 6: 8, 12: "s9", 16: "s5", 17: "s6" },
  { 21: "r10" },
  { 21: "r11" },
  { 13: "r13", 18: "r13", 19: "s26" },
  { 9: 27, 10: 17, 15: "s18" },
  { 13: "r15", 18: "r15", 19: "r15" },
  { 11: "s29" },
  { 13: "r16", 18: "r16", 19: "r16" },
];

/**
 * Parsing stack.
 */
const stack = [];

/**
 * Tokenizer instance.
 */
let tokenizer;
/**
 * Generic tokenizer used by the parser in the Syntax tool.
 *
 * https://www.npmjs.com/package/syntax-cli
 *
 * See `--custom-tokinzer` to skip this generation, and use a custom one.
 */

const lexRules = [
  [
    /^show/,
    function () {
      return "'show'";
    },
  ],
  [
    /^useExperiment/,
    function () {
      return "'useExperiment'";
    },
  ],
  [
    /^or/,
    function () {
      return "'or'";
    },
  ],
  [
    /^and/,
    function () {
      return "'and'";
    },
  ],
  [
    /^equal/,
    function () {
      return "'equal'";
    },
  ],
  [
    /^\bif\b/,
    function () {
      return "IF";
    },
  ],
  [
    /^\bthen\b/,
    function () {
      return "THEN";
    },
  ],
  [
    /^\belse\b/,
    function () {
      return "ELSE";
    },
  ],
  [
    /^\s+/,
    function () {
      /* skip whitespace */
    },
  ],
  [
    /^"[^\"]*"/,
    function () {
      return "STRING";
    },
  ],
  [
    /^\d+/,
    function () {
      return "NUMBER";
    },
  ],
  [
    /^\w+/,
    function () {
      return "IDENTIFIER";
    },
  ],
  [
    /^[+\-]/,
    function () {
      return "ADDITIVE_OPERATOR";
    },
  ],
  [
    /^[*/]/,
    function () {
      return "MULTIPLICATIVE_OPERATOR";
    },
  ],
];
const lexRulesByConditions = {
  INITIAL: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],
};

const EOF_TOKEN = {
  type: EOF,
  value: "",
};

tokenizer = {
  initString(string) {
    this._string = string;
    this._cursor = 0;

    this._states = ["INITIAL"];
    this._tokensQueue = [];

    this._currentLine = 1;
    this._currentColumn = 0;
    this._currentLineBeginOffset = 0;

    /**
     * Matched token location data.
     */
    this._tokenStartOffset = 0;
    this._tokenEndOffset = 0;
    this._tokenStartLine = 1;
    this._tokenEndLine = 1;
    this._tokenStartColumn = 0;
    this._tokenEndColumn = 0;

    return this;
  },

  /**
   * Returns tokenizer states.
   */
  getStates() {
    return this._states;
  },

  getCurrentState() {
    return this._states[this._states.length - 1];
  },

  pushState(state) {
    this._states.push(state);
  },

  begin(state) {
    this.pushState(state);
  },

  popState() {
    if (this._states.length > 1) {
      return this._states.pop();
    }
    return this._states[0];
  },

  getNextToken() {
    // Something was queued, return it.
    if (this._tokensQueue.length > 0) {
      return this.onToken(this._toToken(this._tokensQueue.shift()));
    }

    if (!this.hasMoreTokens()) {
      return this.onToken(EOF_TOKEN);
    }

    let string = this._string.slice(this._cursor);
    let lexRulesForState = lexRulesByConditions[this.getCurrentState()];

    for (let i = 0; i < lexRulesForState.length; i++) {
      let lexRuleIndex = lexRulesForState[i];
      let lexRule = lexRules[lexRuleIndex];

      let matched = this._match(string, lexRule[0]);

      // Manual handling of EOF token (the end of string). Return it
      // as `EOF` symbol.
      if (string === "" && matched === "") {
        this._cursor++;
      }

      if (matched !== null) {
        yytext = matched;
        yyleng = yytext.length;
        let token = lexRule[1].call(this);

        if (!token) {
          return this.getNextToken();
        }

        // If multiple tokens are returned, save them to return
        // on next `getNextToken` call.

        if (Array.isArray(token)) {
          const tokensToQueue = token.slice(1);
          token = token[0];
          if (tokensToQueue.length > 0) {
            this._tokensQueue.unshift(...tokensToQueue);
          }
        }

        return this.onToken(this._toToken(token, yytext));
      }
    }

    if (this.isEOF()) {
      this._cursor++;
      return EOF_TOKEN;
    }

    this.throwUnexpectedToken(
      string[0],
      this._currentLine,
      this._currentColumn
    );
  },

  /**
   * Throws default "Unexpected token" exception, showing the actual
   * line from the source, pointing with the ^ marker to the bad token.
   * In addition, shows `line:column` location.
   */
  throwUnexpectedToken(symbol, line, column) {
    const lineSource = this._string.split("\n")[line - 1];
    let lineData = "";

    if (lineSource) {
      const pad = " ".repeat(column);
      lineData = "\n\n" + lineSource + "\n" + pad + "^\n";
    }

    throw new SyntaxError(
      `${lineData}Unexpected token: "${symbol}" ` + `at ${line}:${column}.`
    );
  },

  getCursor() {
    return this._cursor;
  },

  getCurrentLine() {
    return this._currentLine;
  },

  getCurrentColumn() {
    return this._currentColumn;
  },

  _captureLocation(matched) {
    const nlRe = /\n/g;

    // Absolute offsets.
    this._tokenStartOffset = this._cursor;

    // Line-based locations, start.
    this._tokenStartLine = this._currentLine;
    this._tokenStartColumn =
      this._tokenStartOffset - this._currentLineBeginOffset;

    // Extract `\n` in the matched token.
    let nlMatch;
    while ((nlMatch = nlRe.exec(matched)) !== null) {
      this._currentLine++;
      this._currentLineBeginOffset = this._tokenStartOffset + nlMatch.index + 1;
    }

    this._tokenEndOffset = this._cursor + matched.length;

    // Line-based locations, end.
    this._tokenEndLine = this._currentLine;
    this._tokenEndColumn = this._currentColumn =
      this._tokenEndOffset - this._currentLineBeginOffset;
  },

  _toToken(tokenType, yytext = "") {
    return {
      // Basic data.
      type: tokenType,
      value: yytext,

      // Location data.
      startOffset: this._tokenStartOffset,
      endOffset: this._tokenEndOffset,
      startLine: this._tokenStartLine,
      endLine: this._tokenEndLine,
      startColumn: this._tokenStartColumn,
      endColumn: this._tokenEndColumn,
    };
  },

  isEOF() {
    return this._cursor === this._string.length;
  },

  hasMoreTokens() {
    return this._cursor <= this._string.length;
  },

  _match(string, regexp) {
    let matched = string.match(regexp);
    if (matched) {
      // Handle `\n` in the matched token to track line numbers.
      this._captureLocation(matched[0]);
      this._cursor += matched[0].length;
      return matched[0];
    }
    return null;
  },

  /**
   * Allows analyzing, and transforming token. Default implementation
   * just passes the token through.
   */
  onToken(token) {
    return token;
  },
};

/**
 * Expose tokenizer so it can be accessed in semantic actions.
 */
yy.lexer = tokenizer;
yy.tokenizer = tokenizer;

/**
 * Global parsing options. Some options can be shadowed per
 * each `parse` call, if the optations are passed.
 *
 * Initalized to the `captureLocations` which is passed
 * from the generator. Other options can be added at runtime.
 */
yy.options = {
  captureLocations: false,
};

/**
 * Parsing module.
 */
const yyparse = {
  /**
   * Sets global parsing options.
   */
  setOptions(options) {
    yy.options = options;
    return this;
  },

  /**
   * Returns parsing options.
   */
  getOptions() {
    return yy.options;
  },

  /**
   * Parses a string.
   */
  parse(string, parseOptions) {
    if (!tokenizer) {
      throw new Error(`Tokenizer instance wasn't specified.`);
    }

    tokenizer.initString(string);

    /**
     * If parse options are passed, override global parse options for
     * this call, and later restore global options.
     */
    let globalOptions = yy.options;
    if (parseOptions) {
      yy.options = Object.assign({}, yy.options, parseOptions);
    }

    /**
     * Allow callers to do setup work based on the
     * parsing string, and passed options.
     */
    yyparse.onParseBegin(string, tokenizer, yy.options);

    stack.length = 0;
    stack.push(0);

    let token = tokenizer.getNextToken();
    let shiftedToken = null;

    do {
      if (!token) {
        // Restore options.
        yy.options = globalOptions;
        unexpectedEndOfInput();
      }

      let state = stack[stack.length - 1];
      let column = tokens[token.type];

      if (!table[state].hasOwnProperty(column)) {
        yy.options = globalOptions;
        unexpectedToken(token);
      }

      let entry = table[state][column];

      // Shift action.
      if (entry[0] === "s") {
        let loc = null;

        if (yy.options.captureLocations) {
          loc = {
            startOffset: token.startOffset,
            endOffset: token.endOffset,
            startLine: token.startLine,
            endLine: token.endLine,
            startColumn: token.startColumn,
            endColumn: token.endColumn,
          };
        }

        shiftedToken = this.onShift(token);

        stack.push(
          {
            symbol: tokens[shiftedToken.type],
            semanticValue: shiftedToken.value,
            loc,
          },
          Number(entry.slice(1))
        );

        token = tokenizer.getNextToken();
      }

      // Reduce action.
      else if (entry[0] === "r") {
        let productionNumber = entry.slice(1);
        let production = productions[productionNumber];
        let hasSemanticAction = typeof production[2] === "function";
        let semanticValueArgs = hasSemanticAction ? [] : null;

        const locationArgs =
          hasSemanticAction && yy.options.captureLocations ? [] : null;

        if (production[1] !== 0) {
          let rhsLength = production[1];
          while (rhsLength-- > 0) {
            stack.pop();
            let stackEntry = stack.pop();

            if (hasSemanticAction) {
              semanticValueArgs.unshift(stackEntry.semanticValue);

              if (locationArgs) {
                locationArgs.unshift(stackEntry.loc);
              }
            }
          }
        }

        const reduceStackEntry = { symbol: production[0] };

        if (hasSemanticAction) {
          yytext = shiftedToken ? shiftedToken.value : null;
          yyleng = shiftedToken ? shiftedToken.value.length : null;

          const semanticActionArgs =
            locationArgs !== null
              ? semanticValueArgs.concat(locationArgs)
              : semanticValueArgs;

          production[2](...semanticActionArgs);

          reduceStackEntry.semanticValue = __;

          if (locationArgs) {
            reduceStackEntry.loc = __loc;
          }
        }

        const nextState = stack[stack.length - 1];
        const symbolToReduceWith = production[0];

        stack.push(reduceStackEntry, table[nextState][symbolToReduceWith]);
      }

      // Accept.
      else if (entry === "acc") {
        stack.pop();
        let parsed = stack.pop();

        if (stack.length !== 1 || stack[0] !== 0 || tokenizer.hasMoreTokens()) {
          // Restore options.
          yy.options = globalOptions;
          unexpectedToken(token);
        }

        if (parsed.hasOwnProperty("semanticValue")) {
          yy.options = globalOptions;
          yyparse.onParseEnd(parsed.semanticValue);
          return parsed.semanticValue;
        }

        yyparse.onParseEnd();

        // Restore options.
        yy.options = globalOptions;
        return true;
      }
    } while (tokenizer.hasMoreTokens() || stack.length > 1);
  },

  setTokenizer(customTokenizer) {
    tokenizer = customTokenizer;
    return yyparse;
  },

  getTokenizer() {
    return tokenizer;
  },

  onParseBegin(string, tokenizer, options) {},
  onParseEnd(parsed) {},

  /**
   * Allows analyzing, and transforming shifted token. Default implementation
   * just passes the token through.
   */
  onShift(token) {
    return token;
  },
};

/**
 * Creates generic binary expression node.
 */
function LogicalExpression(left, operator, right) {
  return {
    type: "LogicalExpression",
    operator,
    left,
    right,
  };
}

function unexpectedToken(token) {
  if (token.type === EOF) {
    unexpectedEndOfInput();
  }

  tokenizer.throwUnexpectedToken(
    token.value,
    token.startLine,
    token.startColumn
  );
}

function unexpectedEndOfInput() {
  parseError(`Unexpected end of input.`);
}

function parseError(message) {
  throw new SyntaxError(message);
}

export const Parser = yyparse;
